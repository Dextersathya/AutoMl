{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_FtRAOeLs44",
        "outputId": "d4c8ed6f-5c93-4581-c59f-a3718e48d9c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.10/dist-packages (1.39.0)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: numpy<3,>=1.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.26.4)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.1)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (10.4.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (17.0.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.9.2)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.12.2)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.1.43)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Requirement already satisfied: watchdog<6,>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.0.3)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (1.0.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.8.30)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.1)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.20.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VbrDob6PQc4n",
        "outputId": "14f6ed9f-556f-4315-fb0d-3f4746e602df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing requiredment.txt\n"
          ]
        }
      ],
      "source": [
        "%%writefile requiredment.txt\n",
        "alembic==1.8.1\n",
        "altair==4.2.0\n",
        "asttokens==2.0.8\n",
        "attrs==22.1.0\n",
        "backcall==0.2.0\n",
        "blinker==1.5\n",
        "blis==0.7.9\n",
        "Boruta==0.3\n",
        "cachetools==5.2.0\n",
        "catalogue==1.0.2\n",
        "certifi==2022.9.24\n",
        "charset-normalizer==2.1.1\n",
        "click==8.1.3\n",
        "cloudpickle==2.2.0\n",
        "colorama==0.4.6\n",
        "colorlover==0.3.0\n",
        "commonmark==0.9.1\n",
        "cufflinks==0.17.3\n",
        "cycler==0.11.0\n",
        "cymem==2.0.7\n",
        "databricks-cli==0.17.3\n",
        "debugpy==1.6.3\n",
        "decorator==5.1.1\n",
        "docker==6.0.0\n",
        "entrypoints==0.4\n",
        "executing==1.1.1\n",
        "Flask==2.2.2\n",
        "fonttools==4.38.0\n",
        "funcy==1.17\n",
        "future==0.18.2\n",
        "gensim==3.8.3\n",
        "gitdb==4.0.9\n",
        "GitPython==3.1.29\n",
        "greenlet==1.1.3.post0\n",
        "htmlmin==0.1.12\n",
        "idna==3.4\n",
        "ImageHash==4.3.1\n",
        "imbalanced-learn==0.7.0\n",
        "importlib-metadata==5.0.0\n",
        "ipykernel==6.16.2\n",
        "ipython==8.5.0\n",
        "ipywidgets==8.0.2\n",
        "itsdangerous==2.1.2\n",
        "jedi==0.18.1\n",
        "Jinja2==3.1.2\n",
        "joblib==1.2.0\n",
        "jsonschema==4.16.0\n",
        "jupyter_client==7.4.4\n",
        "jupyter_core==4.11.2\n",
        "jupyterlab-widgets==3.0.3\n",
        "kiwisolver==1.4.4\n",
        "kmodes==0.12.2\n",
        "lightgbm==3.3.3\n",
        "llvmlite==0.37.0\n",
        "Mako==1.2.3\n",
        "MarkupSafe==2.1.1\n",
        "matplotlib==3.5.3\n",
        "matplotlib-inline==0.1.6\n",
        "missingno==0.5.1\n",
        "mlflow==1.30.0\n",
        "mlxtend==0.19.0\n",
        "multimethod==1.9\n",
        "murmurhash==1.0.9\n",
        "nest-asyncio==1.5.6\n",
        "networkx==2.8.7\n",
        "nltk==3.7\n",
        "numba==0.54.1\n",
        "numexpr==2.8.3\n",
        "numpy==1.20.3\n",
        "oauthlib==3.2.2\n",
        "packaging==21.3\n",
        "pandas==1.5.1\n",
        "pandas-profiling==3.4.0\n",
        "parso==0.8.3\n",
        "patsy==0.5.3\n",
        "phik==0.12.2\n",
        "pickleshare==0.7.5\n",
        "Pillow==9.2.0\n",
        "plac==1.1.3\n",
        "plotly==5.10.0\n",
        "preshed==3.0.8\n",
        "prometheus-client==0.15.0\n",
        "prometheus-flask-exporter==0.20.3\n",
        "prompt-toolkit==3.0.31\n",
        "protobuf==3.20.3\n",
        "psutil==5.9.3\n",
        "pure-eval==0.2.2\n",
        "pyarrow==9.0.0\n",
        "pycaret==2.3.10\n",
        "pydantic==1.10.2\n",
        "pydeck==0.8.0b4\n",
        "Pygments==2.13.0\n",
        "PyJWT==2.6.0\n",
        "pyLDAvis==3.3.1\n",
        "Pympler==1.0.1\n",
        "pynndescent==0.5.7\n",
        "pyod==1.0.6\n",
        "pyparsing==3.0.9\n",
        "pyrsistent==0.18.1\n",
        "python-dateutil==2.8.2\n",
        "pytz==2022.5\n",
        "pytz-deprecation-shim==0.1.0.post0\n",
        "PyWavelets==1.4.1\n",
        "pywin32==304\n",
        "PyYAML==5.4.1\n",
        "pyzmq==24.0.1\n",
        "querystring-parser==1.2.4\n",
        "regex==2022.9.13\n",
        "requests==2.28.1\n",
        "rich==12.6.0\n",
        "scikit-learn==0.23.2\n",
        "scikit-plot==0.3.7\n",
        "scipy==1.5.4\n",
        "seaborn==0.12.1\n",
        "semver==2.13.0\n",
        "six==1.16.0\n",
        "sklearn==0.0\n",
        "smart-open==6.2.0\n",
        "smmap==5.0.0\n",
        "spacy==2.3.8\n",
        "SQLAlchemy==1.4.42\n",
        "sqlparse==0.4.3\n",
        "srsly==1.0.6\n",
        "stack-data==0.5.1\n",
        "statsmodels==0.13.2\n",
        "streamlit==1.13.0\n",
        "streamlit-pandas-profiling==0.1.3\n",
        "tabulate==0.9.0\n",
        "tangled-up-in-unicode==0.2.0\n",
        "tenacity==8.1.0\n",
        "textblob==0.17.1\n",
        "thinc==7.4.6\n",
        "threadpoolctl==3.1.0\n",
        "toml==0.10.2\n",
        "toolz==0.12.0\n",
        "tornado==6.2\n",
        "tqdm==4.64.1\n",
        "traitlets==5.5.0\n",
        "typing_extensions==4.4.0\n",
        "tzdata==2022.5\n",
        "tzlocal==4.2\n",
        "umap-learn==0.5.3\n",
        "urllib3==1.26.12\n",
        "validators==0.20.0\n",
        "visions==0.7.5\n",
        "waitress==2.1.2\n",
        "wasabi==0.10.1\n",
        "watchdog==2.1.9\n",
        "wcwidth==0.2.5\n",
        "websocket-client==1.4.1\n",
        "Werkzeug==2.2.2\n",
        "widgetsnbextension==4.0.3\n",
        "wordcloud==1.8.2.2\n",
        "yellowbrick==1.2.1\n",
        "zipp==3.10.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-upQKVaON_w",
        "outputId": "0b671656-b34e-404f-b014-0aa389440c08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting alembic==1.8.1 (from -r requiredment.txt (line 1))\n",
            "  Downloading alembic-1.8.1-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting altair==4.2.0 (from -r requiredment.txt (line 2))\n",
            "  Downloading altair-4.2.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting asttokens==2.0.8 (from -r requiredment.txt (line 3))\n",
            "  Downloading asttokens-2.0.8-py2.py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting attrs==22.1.0 (from -r requiredment.txt (line 4))\n",
            "  Downloading attrs-22.1.0-py2.py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: backcall==0.2.0 in /usr/local/lib/python3.10/dist-packages (from -r requiredment.txt (line 5)) (0.2.0)\n",
            "Collecting blinker==1.5 (from -r requiredment.txt (line 6))\n",
            "  Downloading blinker-1.5-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting blis==0.7.9 (from -r requiredment.txt (line 7))\n",
            "  Downloading blis-0.7.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\n",
            "Collecting Boruta==0.3 (from -r requiredment.txt (line 8))\n",
            "  Downloading Boruta-0.3-py3-none-any.whl.metadata (7.7 kB)\n",
            "Collecting cachetools==5.2.0 (from -r requiredment.txt (line 9))\n",
            "  Downloading cachetools-5.2.0-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting catalogue==1.0.2 (from -r requiredment.txt (line 10))\n",
            "  Downloading catalogue-1.0.2-py2.py3-none-any.whl.metadata (13 kB)\n",
            "Collecting certifi==2022.9.24 (from -r requiredment.txt (line 11))\n",
            "  Downloading certifi-2022.9.24-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting charset-normalizer==2.1.1 (from -r requiredment.txt (line 12))\n",
            "  Downloading charset_normalizer-2.1.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting click==8.1.3 (from -r requiredment.txt (line 13))\n",
            "  Downloading click-8.1.3-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting cloudpickle==2.2.0 (from -r requiredment.txt (line 14))\n",
            "  Downloading cloudpickle-2.2.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting colorama==0.4.6 (from -r requiredment.txt (line 15))\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Collecting colorlover==0.3.0 (from -r requiredment.txt (line 16))\n",
            "  Downloading colorlover-0.3.0-py3-none-any.whl.metadata (421 bytes)\n",
            "Collecting commonmark==0.9.1 (from -r requiredment.txt (line 17))\n",
            "  Downloading commonmark-0.9.1-py2.py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting cufflinks==0.17.3 (from -r requiredment.txt (line 18))\n",
            "  Downloading cufflinks-0.17.3.tar.gz (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.7/81.7 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting cycler==0.11.0 (from -r requiredment.txt (line 19))\n",
            "  Downloading cycler-0.11.0-py3-none-any.whl.metadata (785 bytes)\n",
            "Collecting cymem==2.0.7 (from -r requiredment.txt (line 20))\n",
            "  Downloading cymem-2.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
            "Collecting databricks-cli==0.17.3 (from -r requiredment.txt (line 21))\n",
            "  Downloading databricks-cli-0.17.3.tar.gz (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting debugpy==1.6.3 (from -r requiredment.txt (line 22))\n",
            "  Downloading debugpy-1.6.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: decorator==5.1.1 in /usr/local/lib/python3.10/dist-packages (from -r requiredment.txt (line 23)) (5.1.1)\n",
            "Collecting docker==6.0.0 (from -r requiredment.txt (line 24))\n",
            "  Downloading docker-6.0.0-py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: entrypoints==0.4 in /usr/local/lib/python3.10/dist-packages (from -r requiredment.txt (line 25)) (0.4)\n",
            "Collecting executing==1.1.1 (from -r requiredment.txt (line 26))\n",
            "  Downloading executing-1.1.1-py2.py3-none-any.whl.metadata (8.9 kB)\n",
            "Collecting Flask==2.2.2 (from -r requiredment.txt (line 27))\n",
            "  Downloading Flask-2.2.2-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting fonttools==4.38.0 (from -r requiredment.txt (line 28))\n",
            "  Downloading fonttools-4.38.0-py3-none-any.whl.metadata (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m801.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting funcy==1.17 (from -r requiredment.txt (line 29))\n",
            "  Downloading funcy-1.17-py2.py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting future==0.18.2 (from -r requiredment.txt (line 30))\n",
            "  Downloading future-0.18.2.tar.gz (829 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m829.2/829.2 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gensim==3.8.3 (from -r requiredment.txt (line 31))\n",
            "  Downloading gensim-3.8.3.tar.gz (23.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.4/23.4 MB\u001b[0m \u001b[31m72.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gitdb==4.0.9 (from -r requiredment.txt (line 32))\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl.metadata (998 bytes)\n",
            "Collecting GitPython==3.1.29 (from -r requiredment.txt (line 33))\n",
            "  Downloading GitPython-3.1.29-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting greenlet==1.1.3.post0 (from -r requiredment.txt (line 34))\n",
            "  Downloading greenlet-1.1.3.post0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
            "Collecting htmlmin==0.1.12 (from -r requiredment.txt (line 35))\n",
            "  Downloading htmlmin-0.1.12.tar.gz (19 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting idna==3.4 (from -r requiredment.txt (line 36))\n",
            "  Downloading idna-3.4-py3-none-any.whl.metadata (9.8 kB)\n",
            "Collecting ImageHash==4.3.1 (from -r requiredment.txt (line 37))\n",
            "  Downloading ImageHash-4.3.1-py2.py3-none-any.whl.metadata (8.0 kB)\n",
            "Collecting imbalanced-learn==0.7.0 (from -r requiredment.txt (line 38))\n",
            "  Downloading imbalanced_learn-0.7.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting importlib-metadata==5.0.0 (from -r requiredment.txt (line 39))\n",
            "  Downloading importlib_metadata-5.0.0-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting ipykernel==6.16.2 (from -r requiredment.txt (line 40))\n",
            "  Downloading ipykernel-6.16.2-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting ipython==8.5.0 (from -r requiredment.txt (line 41))\n",
            "  Downloading ipython-8.5.0-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting ipywidgets==8.0.2 (from -r requiredment.txt (line 42))\n",
            "  Downloading ipywidgets-8.0.2-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting itsdangerous==2.1.2 (from -r requiredment.txt (line 43))\n",
            "  Downloading itsdangerous-2.1.2-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting jedi==0.18.1 (from -r requiredment.txt (line 44))\n",
            "  Downloading jedi-0.18.1-py2.py3-none-any.whl.metadata (20 kB)\n",
            "Collecting Jinja2==3.1.2 (from -r requiredment.txt (line 45))\n",
            "  Downloading Jinja2-3.1.2-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting joblib==1.2.0 (from -r requiredment.txt (line 46))\n",
            "  Downloading joblib-1.2.0-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting jsonschema==4.16.0 (from -r requiredment.txt (line 47))\n",
            "  Downloading jsonschema-4.16.0-py3-none-any.whl.metadata (7.8 kB)\n",
            "Collecting jupyter_client==7.4.4 (from -r requiredment.txt (line 48))\n",
            "  Downloading jupyter_client-7.4.4-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting jupyter_core==4.11.2 (from -r requiredment.txt (line 49))\n",
            "  Downloading jupyter_core-4.11.2-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting jupyterlab-widgets==3.0.3 (from -r requiredment.txt (line 50))\n",
            "  Downloading jupyterlab_widgets-3.0.3-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting kiwisolver==1.4.4 (from -r requiredment.txt (line 51))\n",
            "  Downloading kiwisolver-1.4.4-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.3 kB)\n",
            "Collecting kmodes==0.12.2 (from -r requiredment.txt (line 52))\n",
            "  Downloading kmodes-0.12.2-py2.py3-none-any.whl.metadata (8.1 kB)\n",
            "Collecting lightgbm==3.3.3 (from -r requiredment.txt (line 53))\n",
            "  Downloading lightgbm-3.3.3-py3-none-manylinux1_x86_64.whl.metadata (15 kB)\n",
            "\u001b[31mERROR: Ignored the following versions that require a different python version: 0.36.0 Requires-Python >=3.6,<3.10; 0.37.0 Requires-Python >=3.7,<3.10\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement llvmlite==0.37.0 (from versions: 0.2.0, 0.2.1, 0.2.2, 0.4.0, 0.5.0, 0.6.0, 0.7.0, 0.8.0, 0.9.0, 0.10.0, 0.11.0, 0.12.0.1, 0.12.1, 0.13.0, 0.14.0, 0.15.0, 0.16.0, 0.17.0, 0.17.1, 0.18.0, 0.19.0, 0.20.0, 0.21.0, 0.22.0, 0.23.0, 0.23.2, 0.24.0, 0.25.0, 0.26.0, 0.27.0, 0.27.1, 0.28.0, 0.29.0, 0.30.0, 0.31.0, 0.32.0, 0.32.1, 0.33.0, 0.34.0, 0.35.0, 0.38.0, 0.38.1, 0.39.0, 0.39.1, 0.40.0rc1, 0.40.0, 0.40.1rc1, 0.40.1, 0.41.0rc1, 0.41.0, 0.41.1, 0.42.0rc1, 0.42.0, 0.43.0rc1, 0.43.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for llvmlite==0.37.0\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -r requiredment.txt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXnXikKmq15x",
        "outputId": "a023a728-b857-4744-b4d2-cc6daabf30c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "# Create the Streamlit app script\n",
        "%%writefile app.py\n",
        "from operator import index\n",
        "import plotly.express as px\n",
        "from pycaret.regression import setup, compare_models, pull, save_model, load_model\n",
        "import pandas_profiling\n",
        "from streamlit_pandas_profiling import st_profile_report\n",
        "import pandas as pd\n",
        "import streamlit as st\n",
        "import os\n",
        "from ydata_profiling import ProfileReport\n",
        "from streamlit_pandas_profiling import st_profile_report\n",
        "from tpot import TPOTClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "st.title(\"Binary classification model\")\n",
        "\n",
        "# Title\n",
        "\n",
        "\n",
        "\n",
        "with st.sidebar:\n",
        "    st.image(\"file.png\")\n",
        "    st.title(\"autostreamml\")\n",
        "    choice=st.radio(\"Navigation\",[\"upload\",\"profiling\",\"ml\",\"download\"])\n",
        "    st.info(\"this application you to build a automate using auto ml\")\n",
        "    \n",
        "# Necessary detial in side bar\n",
        "    \n",
        "    \n",
        "    \n",
        "\n",
        "\n",
        "if os.path.exists(\"sourcedata.csv\"):\n",
        "    df=pd.read_csv(\"sourcedata.csv\",index_col=None)\n",
        "    \n",
        "# retriving source data\n",
        "    \n",
        "\n",
        "    \n",
        "if choice == \"upload\":\n",
        "    file=st.file_uploader(\"upload your Dataset Here\")\n",
        "    if file:\n",
        "        df=pd.read_csv(file,index_col=None)\n",
        "        df.to_csv(\"sourcedata.csv\",index=None)\n",
        "        st.dataframe(df)\n",
        "        \n",
        "# uploading a csv file\n",
        "        \n",
        "        \n",
        "if choice == \"profiling\":\n",
        "    st.title(\"exploratory data analysis\")\n",
        "    Profile_report=ProfileReport(df)\n",
        "    st_profile_report(Profile_report)\n",
        "    \n",
        "    \n",
        "# profiling for the data analysist the data\n",
        "    \n",
        "if choice == \"ml\":\n",
        "    st.title(\"automated ml model\")\n",
        "    \n",
        "    chosen_target = st.selectbox('Choose the Target Column', df.columns)\n",
        "    \n",
        "    available_features = df.columns[df.columns != chosen_target].tolist()  # Exclude the target column\n",
        "    selected_features = st.multiselect('Select Independent Variables', available_features)\n",
        "    \n",
        "    # selecting the target value\n",
        "    \n",
        "    if st.button('Run Modelling'):\n",
        "        if not selected_features:\n",
        "            st.error(\"Please select at least one independent variable.\")\n",
        "        else:\n",
        "            X = df[selected_features]  # Selected independent variables\n",
        "            y = df[chosen_target]  # Target variable\n",
        "        # spliting dependent and independent columns\n",
        "        \n",
        "            if y.dtype == 'object':  # Check if target is categorical\n",
        "                le = LabelEncoder()\n",
        "                y = le.fit_transform(y)\n",
        "            elif y.dtype == 'bool':  # Convert boolean target to integer (0, 1)\n",
        "                y = y.astype(int)\n",
        "            \n",
        "         \n",
        "         \n",
        "        #spliting the data train test\n",
        "        \n",
        "        numeric_cols = X.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
        "        categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
        "        boolean_cols = X.select_dtypes(include=['bool']).columns.tolist()\n",
        "        \n",
        "        #based on the catagory spliting the data    \n",
        "         \n",
        "         \n",
        "        X[boolean_cols] = X[boolean_cols].astype(int)\n",
        "         \n",
        "            \n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "        \n",
        "        \n",
        "        # Preprocessing for numeric data (impute with median)\n",
        "        numeric_transformer = Pipeline(steps=[\n",
        "        ('imputer', SimpleImputer(strategy='median'))\n",
        "        ])\n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        # Preprocessing for categorical data (impute with most frequent and one-hot encode, with sparse_output=False)\n",
        "        categorical_transformer = Pipeline(steps=[\n",
        "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "        ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
        "        ])\n",
        "        \n",
        "        \n",
        "        # Bundle preprocessing for numeric and categorical data\n",
        "        preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "        ('num', numeric_transformer, numeric_cols),\n",
        "        ('cat', categorical_transformer, categorical_cols)\n",
        "        ])\n",
        "        \n",
        "        \n",
        "        \n",
        "        # Create a pipeline with preprocessing and TPOT classifier\n",
        "        model_pipeline = Pipeline(steps=[\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('classifier', TPOTClassifier(verbosity=2, generations=5, population_size=20, random_state=42))\n",
        "        ])\n",
        "        \n",
        "        \n",
        "        # Train the model pipeline\n",
        "        model_pipeline.fit(X_train, y_train)\n",
        "        \n",
        "        accuracy = model_pipeline.score(X_test, y_test)\n",
        "        \n",
        "        \n",
        "        st.write(f\"Model Accuracy: {accuracy}\")\n",
        "\n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        st.info(\"Training TPOT AutoML model, this might take a few minutes...\")\n",
        "        \n",
        "        accuracy = model_pipeline.score(X_test, y_test)\n",
        "        st.success(f\"Model trained with Test Accuracy: {accuracy:.2%}\")\n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        tpot_classifier = model_pipeline.named_steps['classifier']\n",
        "        \n",
        "\n",
        "        # Check if it is indeed a TPOTClassifier\n",
        "        if isinstance(tpot_classifier, TPOTClassifier):\n",
        "        # Export the best model pipeline\n",
        "            tpot_classifier.export('best_model_pipeline.py')\n",
        "        \n",
        "    \n",
        "        else:\n",
        "            st.error(\"The model is not a TPOTClassifier.\")\n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        st.info(\"The best model pipeline has been exported as 'best_model_pipeline.py'.\")\n",
        "        st.text(\"Optimized Model Pipeline: \")\n",
        "        with open('best_model_pipeline.py', 'r') as file:\n",
        "            st.code(file.read(), language='python')\n",
        "            \n",
        "            \n",
        "if choice ==\"download\":\n",
        "\n",
        "    if os.path.exists('best_model_pipeline.py'):\n",
        "        st.text(\"Optimized Model Pipeline: \")\n",
        "        with open('best_model_pipeline.py', 'r') as file:\n",
        "            st.code(file.read(), language='python')\n",
        "\n",
        "        # Provide a download button\n",
        "        with open('best_model_pipeline.py', 'rb') as f:\n",
        "            st.download_button(\n",
        "                label=\"Download Best Model Pipeline\",\n",
        "                data=f,\n",
        "                file_name='best_model_pipeline.py',\n",
        "                mime='text/x-python'\n",
        "            )\n",
        "    else:\n",
        "        st.error(\"No pipeline has been created yet. Please run the model first.\")\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rm4Ugyuk5UYQ",
        "outputId": "f5e42c98-b122-4b6a-ecbc-1a6a3c144fc9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting autokeras\n",
            "  Downloading autokeras-2.0.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from autokeras) (24.1)\n",
            "Collecting keras-tuner>=1.4.0 (from autokeras)\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting keras-nlp>=0.8.0 (from autokeras)\n",
            "  Downloading keras_nlp-0.15.1-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting keras>=3.0.0 (from autokeras)\n",
            "  Downloading keras-3.6.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from autokeras) (0.1.8)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->autokeras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->autokeras) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->autokeras) (13.9.2)\n",
            "Collecting namex (from keras>=3.0.0->autokeras)\n",
            "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->autokeras) (3.12.1)\n",
            "Collecting optree (from keras>=3.0.0->autokeras)\n",
            "  Downloading optree-0.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (47 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.8/47.8 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->autokeras) (0.2.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from keras-nlp>=0.8.0->autokeras) (2024.9.11)\n",
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.10/dist-packages (from keras-nlp>=0.8.0->autokeras) (0.3.1)\n",
            "Requirement already satisfied: tensorflow-text in /usr/local/lib/python3.10/dist-packages (from keras-nlp>=0.8.0->autokeras) (2.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner>=1.4.0->autokeras) (2.32.3)\n",
            "Collecting kt-legacy (from keras-tuner>=1.4.0->autokeras)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kagglehub->keras-nlp>=0.8.0->autokeras) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras>=3.0.0->autokeras) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner>=1.4.0->autokeras) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner>=1.4.0->autokeras) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner>=1.4.0->autokeras) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner>=1.4.0->autokeras) (2024.8.30)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->autokeras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->autokeras) (2.18.0)\n",
            "Requirement already satisfied: tensorflow-hub>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-text->keras-nlp>=0.8.0->autokeras) (0.16.1)\n",
            "Requirement already satisfied: tensorflow<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-text->keras-nlp>=0.8.0->autokeras) (2.15.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->autokeras) (0.1.2)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp>=0.8.0->autokeras) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp>=0.8.0->autokeras) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp>=0.8.0->autokeras) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp>=0.8.0->autokeras) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp>=0.8.0->autokeras) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp>=0.8.0->autokeras) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp>=0.8.0->autokeras) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp>=0.8.0->autokeras) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp>=0.8.0->autokeras) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp>=0.8.0->autokeras) (2.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp>=0.8.0->autokeras) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp>=0.8.0->autokeras) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp>=0.8.0->autokeras) (1.66.2)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp>=0.8.0->autokeras) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp>=0.8.0->autokeras) (2.15.0)\n",
            "INFO: pip is looking at multiple versions of tensorflow to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting tensorflow<2.16,>=2.15.0 (from tensorflow-text->keras-nlp>=0.8.0->autokeras)\n",
            "  Downloading tensorflow-2.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Collecting ml-dtypes (from keras>=3.0.0->autokeras)\n",
            "  Downloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Collecting tensorflow<2.16,>=2.15.0 (from tensorflow-text->keras-nlp>=0.8.0->autokeras)\n",
            "  Downloading tensorflow-2.15.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Collecting tensorflow-text (from keras-nlp>=0.8.0->autokeras)\n",
            "  Downloading tensorflow_text-2.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting tensorflow<2.18,>=2.17.0 (from tensorflow-text->keras-nlp>=0.8.0->autokeras)\n",
            "  Downloading tensorflow-2.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Collecting ml-dtypes (from keras>=3.0.0->autokeras)\n",
            "  Downloading ml_dtypes-0.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Collecting tensorboard<2.18,>=2.17 (from tensorflow<2.18,>=2.17.0->tensorflow-text->keras-nlp>=0.8.0->autokeras)\n",
            "  Downloading tensorboard-2.17.1-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp>=0.8.0->autokeras) (0.44.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17.0->tensorflow-text->keras-nlp>=0.8.0->autokeras) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17.0->tensorflow-text->keras-nlp>=0.8.0->autokeras) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17.0->tensorflow-text->keras-nlp>=0.8.0->autokeras) (3.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17.0->tensorflow-text->keras-nlp>=0.8.0->autokeras) (3.0.1)\n",
            "Downloading autokeras-2.0.0-py3-none-any.whl (122 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.7/122.7 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras-3.6.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras_nlp-0.15.1-py3-none-any.whl (548 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m548.4/548.4 kB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
            "Downloading optree-0.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (358 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m358.9/358.9 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_text-2.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m87.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow-2.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (601.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m601.3/601.3 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ml_dtypes-0.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m69.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.17.1-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m98.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: namex, kt-legacy, optree, ml-dtypes, tensorboard, keras, tensorflow, keras-tuner, tensorflow-text, keras-nlp, autokeras\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.2.0\n",
            "    Uninstalling ml-dtypes-0.2.0:\n",
            "      Successfully uninstalled ml-dtypes-0.2.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.15.2\n",
            "    Uninstalling tensorboard-2.15.2:\n",
            "      Successfully uninstalled tensorboard-2.15.2\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.15.0\n",
            "    Uninstalling keras-2.15.0:\n",
            "      Successfully uninstalled keras-2.15.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.15.0\n",
            "    Uninstalling tensorflow-2.15.0:\n",
            "      Successfully uninstalled tensorflow-2.15.0\n",
            "  Attempting uninstall: tensorflow-text\n",
            "    Found existing installation: tensorflow-text 2.15.0\n",
            "    Uninstalling tensorflow-text-2.15.0:\n",
            "      Successfully uninstalled tensorflow-text-2.15.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.17.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed autokeras-2.0.0 keras-3.6.0 keras-nlp-0.15.1 keras-tuner-1.4.7 kt-legacy-1.0.5 ml-dtypes-0.4.1 namex-0.0.8 optree-0.13.0 tensorboard-2.17.1 tensorflow-2.17.0 tensorflow-text-2.17.0\n"
          ]
        }
      ],
      "source": [
        "!pip install autokeras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-YaM0b-ANdDH"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Launch the Streamlit app in the background\n",
        "!streamlit run app.py &\n",
        "\n",
        "# Create a tunnel using ngrok to access the Streamlit app\n",
        "public_url = ngrok.connect(port='8501')\n",
        "public_url\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "3tgJUwvQJ7cT",
        "outputId": "ee9df230-9113-4ba0-9f5b-51f063cdccd2"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Get your authtoken from the ngrok dashboard and paste it here\n",
        "NGROK_AUTHTOKEN = \"2nOVoAF1CMYFIjdtaD8ilpGTIFV_69UHxHKDrEd4Lq9R1VJvM\"  # Replace with your actual authtoken\n",
        "\n",
        "# Configure pyngrok with your authtoken\n",
        "ngrok.set_auth_token(NGROK_AUTHTOKEN)\n",
        "\n",
        "# Launch the Streamlit app in the background\n",
        "!streamlit run app.py &\n",
        "\n",
        "# Create a tunnel using ngrok to access the Streamlit app\n",
        "# The error was due to missing 'addr' parameter,\n",
        "# 'port' alone is not enough to define the tunnel.\n",
        "# Streamlit runs on port 8501 by default,\n",
        "# so we specify the address explicitly.\n",
        "public_url = ngrok.connect(addr='8501')\n",
        "\n",
        "public_url"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KeEHPFEI_cO",
        "outputId": "3b272982-4ca1-4dcd-dd20-90074a703915"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.0-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\n",
            "Downloading pyngrok-7.2.0-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pyngrok\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 619
        },
        "id": "TgRrTdpy6GoJ",
        "outputId": "f0bad0e8-71d9-429f-a377-eb2f587bf875"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok\n",
        "import subprocess\n",
        "\n",
        "# Step 1: Launch the Streamlit app in the background\n",
        "subprocess.Popen([\"streamlit\", \"run\", \"ap.py\"])\n",
        "\n",
        "# Step 2: Create a tunnel using ngrok to access the Streamlit app\n",
        "public_url = ngrok.connect(8501)\n",
        "print(\"Streamlit app is available at:\", public_url)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
